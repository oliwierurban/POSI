{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/oliwierurban/POSI/blob/main/Cwiczenia8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ćwiczenia 8"
      ],
      "metadata": {
        "id": "j8ER7gHzAgTv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Wprowadzenie"
      ],
      "metadata": {
        "id": "CNy2ld8r2uwo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Jak działa KNN?\n",
        "\n",
        "Algorytm KNN działa na zasadzie porównywania nowych danych z danymi już znanymi (tzw. treningowymi). Jego główną ideą jest to, że obiekty, które są \"blisko siebie\" (tzn. mają podobne cechy), są bardziej podobne do siebie i powinny być klasyfikowane w ten sam sposób. Działa to na zasadzie:\n",
        "\n",
        "1. **Określenie liczby sąsiadów (K)** – użytkownik wybiera liczbę $ K $, czyli ile najbliższych sąsiadów należy brać pod uwagę przy klasyfikacji.\n",
        "2. **Obliczanie odległości** – dla danego punktu (np. nowego przykładu, który chcemy sklasyfikować) algorytm oblicza odległość do wszystkich innych punktów w zbiorze treningowym (zwykle stosuje się metrykę Euklidesową, ale mogą to być inne odległości, jak Manhattan).\n",
        "3. **Wybór K najbliższych sąsiadów** – algorytm wybiera $ K $ punktów z treningowego zbioru danych, które są najbliższe do punktu, który chcemy sklasyfikować.\n",
        "4. **Klasyfikacja/średnia** – na podstawie klasy (dla klasyfikacji) lub wartości (dla regresji) $ K $ najbliższych sąsiadów, algorytm przypisuje etykietę nowemu punktowi. W przypadku klasyfikacji będzie to najczęściej najczęstsza klasa spośród $ K $ sąsiadów, a w przypadku regresji – średnia wartość.\n",
        "\n",
        "<br>\n",
        "\n",
        "#### Przykład:\n",
        "\n",
        "Załóżmy, że masz zbiór danych o kwiatach, z dwoma cechami: długość i szerokość płatków. Chcesz sklasyfikować nowy kwiat. Algorytm KNN znajdzie $ K $ najbardziej podobnych kwiatów w zbiorze treningowym (np. 5 najbliższych) i przypisze nowemu kwiatowi etykietę na podstawie większości (np. \"iris-setosa\", jeśli 3 z 5 najbliższych są setosą).\n",
        "\n",
        "<br>\n",
        "\n",
        "#### Zalety i wady:\n",
        "\n",
        "##### Zalety:\n",
        "- Prosty do zrozumienia i implementacji.\n",
        "- Nie wymaga treningu modelu, działa \"na bieżąco\".\n",
        "- Może być używany do wielu typów danych (np. klasyfikacja, regresja).\n",
        "\n",
        "##### Wady:\n",
        "- **Wydajność obliczeniowa**: im większy zbiór danych, tym więcej operacji.\n",
        "- **Wrażliwość na szum i nieistotne cechy.**\n",
        "- Wymaga odpowiedniej metryki odległości (choć w niektórych przypadkach może być trudne do wyboru).\n"
      ],
      "metadata": {
        "id": "WhehbpCa_FNg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Miary odległości\n",
        "\n",
        "#### 1. Odległość Euklidesowa (Euclidean Distance)\n",
        "\n",
        "Jest to najbardziej powszechnie stosowana metryka, szczególnie w klasycznych zadaniach klasyfikacji i regresji, gdy dane są ciągłe.\n",
        "\n",
        "##### Wzór:\n",
        "\n",
        "$$\n",
        "d_E = \\sqrt{(x_1 - y_1)^2 + (x_2 - y_2)^2 + \\dots + (x_n - y_n)^2}\n",
        "$$\n",
        "\n",
        "Gdzie:\n",
        "\n",
        "- $ x_1, x_2, \\dots, x_n $ to współrzędne punktu $ x $,\n",
        "- $ y_1, y_2, \\dots, y_n $ to współrzędne punktu $ y $,\n",
        "- $ n $ to liczba wymiarów (cech).\n",
        "\n",
        "##### Przykład:\n",
        "\n",
        "Jeśli mamy dwa punkty w 2 wymiarach: $ x = (3, 4) $ i $ y = (7, 1) $, to odległość Euklidesowa między nimi to:\n",
        "\n",
        "$$\n",
        "d_E = \\sqrt{(3 - 7)^2 + (4 - 1)^2} = \\sqrt{(-4)^2 + 3^2} = \\sqrt{16 + 9} = \\sqrt{25} = 5\n",
        "$$\n",
        "\n",
        "<br>\n",
        "\n",
        "#### 2. Odległość Manhattan (Manhattan Distance)\n",
        "\n",
        "Jest to alternatywna miara, która sumuje różnice współrzędnych punktów wzdłuż osi. Jest szczególnie użyteczna, gdy dane są zorganizowane w siatkę (np. w przypadku problemów związanych z ruchem w miastach).\n",
        "\n",
        "##### Wzór:\n",
        "\n",
        "$$\n",
        "d_M = |x_1 - y_1| + |x_2 - y_2| + \\dots + |x_n - y_n|\n",
        "$$\n",
        "\n",
        "##### Przykład:\n",
        "\n",
        "Dla punktów $ x = (3, 4) $ i $ y = (7, 1) $, odległość Manhattan to:\n",
        "\n",
        "$$\n",
        "d_M = |3 - 7| + |4 - 1| = 4 + 3 = 7\n",
        "$$\n",
        "\n",
        "<br>\n",
        "\n",
        "#### 3. Odległość Minkowskiego (Minkowski Distance)\n",
        "\n",
        "Jest ogólną formą obu powyższych metryk. Odległość Minkowskiego może przyjąć różne wartości w zależności od parametru $ p $.\n",
        "\n",
        "##### Wzór:\n",
        "\n",
        "$$\n",
        "d_M = \\left( |x_1 - y_1|^p + |x_2 - y_2|^p + \\dots + |x_n - y_n|^p \\right)^{1/p}\n",
        "$$\n",
        "\n",
        "Gdy $ p = 1 $, odległość Minkowskiego jest równa odległości Manhattan.\n",
        "\n",
        "Gdy $ p = 2 $, jest to odległość Euklidesowa.\n",
        "\n",
        "##### Przykład:\n",
        "\n",
        "Dla punktów $ x = (3, 4) $ i $ y = (7, 1) $, jeśli $ p = 3 $:\n",
        "\n",
        "$$\n",
        "d_M = \\left( |3 - 7|^3 + |4 - 1|^3 \\right)^{1/3} = \\left( 4^3 + 3^3 \\right)^{1/3} = \\left( 64 + 27 \\right)^{1/3} = 91^{1/3} \\approx 4.5\n",
        "$$\n",
        "\n",
        "<br>\n",
        "\n",
        "#### Podsumowanie\n",
        "\n",
        "W zależności od charakterystyki danych i problemu, możesz wybierać odpowiednią metrykę odległości:\n",
        "\n",
        "- **Euklidesowa** – najczęściej stosowana w zadaniach ogólnych (ciągłe dane).\n",
        "- **Manhattan** – dla danych, które dobrze opisują \"ruch\" w siatce.\n",
        "- **Minkowski** – ogólna forma, pozwalająca na eksperymentowanie z parametrem $ p $.\n"
      ],
      "metadata": {
        "id": "d_ut8hYYuI6G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Zadanie 1\n",
        "Dla zbioru danych `load_wine` z modułu `sklearn.datasets` przeprowadź analizę DEA oraz klasyfikację cechy `target` z wykorzystaniem `KNN`. Sprawdź diałanie modelu dla różnych wartości `k-sąsiadów`. Pamiętaj o skalowaniu danych.\n",
        "\n",
        "<br>\n",
        "\n",
        "Przykład ładowania danych:\n",
        "\n",
        "```\n",
        "from sklearn.datasets import load_wine\n",
        "\n",
        "wine = load_wine()\n",
        "\n",
        "X = wine.data\n",
        "y = wine.target\n",
        "```"
      ],
      "metadata": {
        "id": "LtPGz00R2hsq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "from sklearn.datasets import load_wine\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "wine = load_wine()\n",
        "X = wine.data\n",
        "y = wine.target\n",
        "\n",
        "print(\"Kształt X:\", X.shape)\n",
        "print(\"Kształt y:\", y.shape)\n",
        "print(\"Nazwy klas:\", wine.target_names)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=y\n",
        ")\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "k_values = [1, 3, 5, 7, 9, 11]\n",
        "accuracies = []\n",
        "\n",
        "print(\"\\n Porównanie dokładności dla różnych k \")\n",
        "for k in k_values:\n",
        "    knn = KNeighborsClassifier(n_neighbors=k)\n",
        "    knn.fit(X_train_scaled, y_train)\n",
        "    y_pred = knn.predict(X_test_scaled)\n",
        "\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    accuracies.append(acc)\n",
        "    print(f\"k = {k}: accuracy = {acc:.4f}\")\n",
        "\n",
        "best_index = int(np.argmax(accuracies))\n",
        "best_k = k_values[best_index]\n",
        "print(f\"\\nNajlepsze k: {best_k} (accuracy = {accuracies[best_index]:.4f})\")\n",
        "\n",
        "best_knn = KNeighborsClassifier(n_neighbors=best_k)\n",
        "best_knn.fit(X_train_scaled, y_train)\n",
        "y_pred_best = best_knn.predict(X_test_scaled)\n",
        "\n",
        "print(\"\\nMacierz pomyłek dla najlepszego k:\")\n",
        "print(confusion_matrix(y_test, y_pred_best))\n",
        "\n",
        "print(\"\\nRaport klasyfikacji dla najlepszego k:\")\n",
        "print(classification_report(y_test, y_pred_best, target_names=wine.target_names))"
      ],
      "metadata": {
        "id": "HuifYZPsGaOL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Zadanie 2\n",
        "Dla zbioru danych `fetch_california_housing` z modułu `sklearn.datasets` przeprowadź analizę DEA oraz regresję z wykorzystaniem `KNN`. Sprawdź diałanie modelu dla różnych wartości `k-sąsiadów`. Pamiętaj o skalowaniu danych.\n",
        "\n",
        "<br>\n",
        "\n",
        "Przykład ładowania danych:\n",
        "\n",
        "```\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "\n",
        "data = fetch_california_housing()\n",
        "X = data.data\n",
        "y = data.target\n",
        "```"
      ],
      "metadata": {
        "id": "ga00M6JV2Vqh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "data = fetch_california_housing()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "print(\"Kształt X:\", X.shape)\n",
        "print(\"Kształt y:\", y.shape)\n",
        "print(\"Nazwy cech:\", data.feature_names)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y,\n",
        "    test_size=0.2,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "k_values = [1, 3, 5, 7, 9, 11]\n",
        "rmse_scores = []\n",
        "r2_scores = []\n",
        "\n",
        "print(\"\\n Porównanie jakości (RMSE i R2) dla różnych k\")\n",
        "for k in k_values:\n",
        "    knn_reg = KNeighborsRegressor(n_neighbors=k)\n",
        "    knn_reg.fit(X_train_scaled, y_train)\n",
        "\n",
        "    y_pred = knn_reg.predict(X_test_scaled)\n",
        "\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "    rmse = np.sqrt(mse)\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "    rmse_scores.append(rmse)\n",
        "    r2_scores.append(r2)\n",
        "\n",
        "    print(f\"k = {k}: RMSE = {rmse:.4f}, R2 = {r2:.4f}\")\n",
        "\n",
        "best_index_r2 = int(np.argmax(r2_scores))\n",
        "best_k_r2 = k_values[best_index_r2]\n",
        "\n",
        "print(f\"\\nNajlepsze k (pod względem R2): {best_k_r2}\")\n",
        "print(f\"RMSE = {rmse_scores[best_index_r2]:.4f}, R2 = {r2_scores[best_index_r2]:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IwPf_JI5GsDF",
        "outputId": "0b9d5d1c-529c-427c-ae8b-549339bac618"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Kształt X: (20640, 8)\n",
            "Kształt y: (20640,)\n",
            "Nazwy cech: ['MedInc', 'HouseAge', 'AveRooms', 'AveBedrms', 'Population', 'AveOccup', 'Latitude', 'Longitude']\n",
            "\n",
            " Porównanie jakości (RMSE i R2) dla różnych k\n",
            "k = 1: RMSE = 0.8179, R2 = 0.4895\n",
            "k = 3: RMSE = 0.6831, R2 = 0.6439\n",
            "k = 5: RMSE = 0.6576, R2 = 0.6700\n",
            "k = 7: RMSE = 0.6545, R2 = 0.6731\n",
            "k = 9: RMSE = 0.6516, R2 = 0.6760\n",
            "k = 11: RMSE = 0.6470, R2 = 0.6806\n",
            "\n",
            "Najlepsze k (pod względem R2): 11\n",
            "RMSE = 0.6470, R2 = 0.6806\n"
          ]
        }
      ]
    }
  ]
}